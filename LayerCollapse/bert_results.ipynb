{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_models = {\"base\": \"bert-base-uncased\",\n",
    "                        \"large\": \"bert-large-uncased\",\n",
    "                      \"base-ft-sst2\": \"yoshitomo-matsubara/bert-base-uncased-sst2\",\n",
    "                        \"large-ft-sst2\": \"yoshitomo-matsubara/bert-large-uncased-sst2\",\n",
    "                      \"base-ft-stsb\": \"gchhablani/bert-base-cased-finetuned-stsb\",\n",
    "                        \"large-ft-stsb\": \"yoshitomo-matsubara/bert-large-uncased-stsb\",\n",
    "                      \"base-ft-mrpc\": \"textattack/bert-base-uncased-MRPC\",\n",
    "                        \"large-ft-mrpc\": \"yoshitomo-matsubara/bert-large-uncased-mrpc\",\n",
    "                      \"base-ft-cola\": \"yoshitomo-matsubara/bert-base-uncased-cola\",\n",
    "                        \"large-ft-cola\": \"yoshitomo-matsubara/bert-large-uncased-cola\",\n",
    "                      \"base-ft-qnli\": \"gchhablani/bert-base-cased-finetuned-qnli\",\n",
    "                        \"large-ft-qnli\": \"yoshitomo-matsubara/bert-large-uncased-qnli\",\n",
    "                      \"base-ft-mnli\": \"yoshitomo-matsubara/bert-base-uncased-mnli\",\n",
    "                        \"large-ft-mnli\": \"yoshitomo-matsubara/bert-large-uncased-mnli\",\n",
    "                      \"base-ft-rte\": \"anirudh21/bert-base-uncased-finetuned-rte\",\n",
    "                        \"large-ft-rte\": \"gchhablani/bert-large-cased-finetuned-rte\",\n",
    "                      \"base-ft-qqp\": \"A-bhimany-u08/bert-base-cased-qqp\",\n",
    "                        \"large-ft-qqp\": \"yoshitomo-matsubara/bert-large-uncased-qqp\",\n",
    "                      \"base-ft-wnli\": \"gchhablani/bert-base-cased-finetuned-wnli\",\n",
    "                        \"large-ft-wnli\": \"yoshitomo-matsubara/bert-large-uncased-wnli\",\n",
    "                      }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"base-ft-qqp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('qqp', tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-qqp/orig_qqp.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.11\n",
      "Setting up gated layer bert.encoder.layer.10\n",
      "Setting up gated layer bert.encoder.layer.9\n",
      "Setting up gated layer bert.encoder.layer.8\n"
     ]
    }
   ],
   "source": [
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-qqp/4_qqp.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer bert.encoder.layer.11\n",
      "Collapsing layer bert.encoder.layer.10\n",
      "Collapsing layer bert.encoder.layer.9\n",
      "Collapsing layer bert.encoder.layer.8\n"
     ]
    }
   ],
   "source": [
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1264' max='1264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1264/1264 04:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2924763560295105,\n",
       " 'eval_accuracy': 0.8851100667820925,\n",
       " 'eval_f1': 0.8398331092031309,\n",
       " 'eval_combined_score': 0.8624715879926117,\n",
       " 'eval_runtime': 264.3965,\n",
       " 'eval_samples_per_second': 152.914,\n",
       " 'eval_steps_per_second': 4.781}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"qqp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1264' max='1264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1264/1264 02:54]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3376820385456085,\n",
       " 'eval_accuracy': 0.9099183774424932,\n",
       " 'eval_f1': 0.8776127427918543,\n",
       " 'eval_combined_score': 0.8937655601171737,\n",
       " 'eval_runtime': 175.4034,\n",
       " 'eval_samples_per_second': 230.497,\n",
       " 'eval_steps_per_second': 7.206}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"qqp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  108311810\n",
      "LC model parameters:  91784450\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SST2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 3.11M/3.11M [00:00<00:00, 12.8MB/s]\n",
      "Downloading data: 100%|██████████| 72.8k/72.8k [00:00<00:00, 690kB/s]\n",
      "Downloading data: 100%|██████████| 148k/148k [00:00<00:00, 886kB/s]\n",
      "Generating train split: 100%|██████████| 67349/67349 [00:00<00:00, 906708.07 examples/s]\n",
      "Generating validation split: 100%|██████████| 872/872 [00:00<00:00, 154641.79 examples/s]\n",
      "Generating test split: 100%|██████████| 1821/1821 [00:00<00:00, 323581.92 examples/s]\n",
      "Map: 100%|██████████| 67349/67349 [00:17<00:00, 3884.31 examples/s]\n",
      "Map: 100%|██████████| 872/872 [00:00<00:00, 3953.92 examples/s]\n",
      "Map: 100%|██████████| 1821/1821 [00:00<00:00, 3849.85 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.11\n",
      "Setting up gated layer bert.encoder.layer.10\n",
      "Setting up gated layer bert.encoder.layer.9\n",
      "Setting up gated layer bert.encoder.layer.8\n",
      "Collapsing layer bert.encoder.layer.11\n",
      "Collapsing layer bert.encoder.layer.10\n",
      "Collapsing layer bert.encoder.layer.9\n",
      "Collapsing layer bert.encoder.layer.8\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"base-ft-sst2\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('sst2', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-sst2/4_sst2.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-sst2/orig_sst2.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  109483778\n",
      "LC model parameters:  92956418\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.24907992780208588,\n",
       " 'eval_accuracy': 0.926605504587156,\n",
       " 'eval_runtime': 3.5167,\n",
       " 'eval_samples_per_second': 247.962,\n",
       " 'eval_steps_per_second': 7.962}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.320715993642807,\n",
       " 'eval_accuracy': 0.911697247706422,\n",
       " 'eval_runtime': 5.7665,\n",
       " 'eval_samples_per_second': 151.219,\n",
       " 'eval_steps_per_second': 4.856}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"sst2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.11\n",
      "Setting up gated layer bert.encoder.layer.10\n",
      "Setting up gated layer bert.encoder.layer.9\n",
      "Setting up gated layer bert.encoder.layer.8\n",
      "Collapsing layer bert.encoder.layer.11\n",
      "Collapsing layer bert.encoder.layer.10\n",
      "Collapsing layer bert.encoder.layer.9\n",
      "Collapsing layer bert.encoder.layer.8\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"base-ft-mrpc\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('mrpc', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-mrpc/4_mrpc.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-mrpc/orig_mrpc.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  109483778\n",
      "LC model parameters:  92956418\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7286306619644165,\n",
       " 'eval_accuracy': 0.8308823529411765,\n",
       " 'eval_f1': 0.8848080133555927,\n",
       " 'eval_combined_score': 0.8578451831483846,\n",
       " 'eval_runtime': 3.3672,\n",
       " 'eval_samples_per_second': 121.168,\n",
       " 'eval_steps_per_second': 3.861}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7689980864524841,\n",
       " 'eval_accuracy': 0.8627450980392157,\n",
       " 'eval_f1': 0.9044368600682594,\n",
       " 'eval_combined_score': 0.8835909790537375,\n",
       " 'eval_runtime': 2.5633,\n",
       " 'eval_samples_per_second': 159.172,\n",
       " 'eval_steps_per_second': 5.072}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"mrpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.11\n",
      "Setting up gated layer bert.encoder.layer.10\n",
      "Setting up gated layer bert.encoder.layer.9\n",
      "Setting up gated layer bert.encoder.layer.8\n",
      "Collapsing layer bert.encoder.layer.11\n",
      "Collapsing layer bert.encoder.layer.10\n",
      "Collapsing layer bert.encoder.layer.9\n",
      "Collapsing layer bert.encoder.layer.8\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"base-ft-mnli\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('mnli', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-mnli/4_mnli.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-mnli/orig_mnli.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  109484547\n",
      "LC model parameters:  92957187\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='307' max='307' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [307/307 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4682498276233673,\n",
       " 'eval_accuracy': 0.8347427407030056,\n",
       " 'eval_runtime': 35.9389,\n",
       " 'eval_samples_per_second': 273.103,\n",
       " 'eval_steps_per_second': 8.542}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation_matched\"], \"mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='308' max='308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [308/308 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4504593312740326,\n",
       " 'eval_accuracy': 0.8371643612693247,\n",
       " 'eval_runtime': 35.9834,\n",
       " 'eval_samples_per_second': 273.237,\n",
       " 'eval_steps_per_second': 8.559}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation_mismatched\"], \"mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='307' max='307' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [307/307 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5070212483406067,\n",
       " 'eval_accuracy': 0.8254712175241976,\n",
       " 'eval_runtime': 34.7803,\n",
       " 'eval_samples_per_second': 282.2,\n",
       " 'eval_steps_per_second': 8.827}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation_matched\"], \"mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='308' max='308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [308/308 00:34]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4870189428329468,\n",
       " 'eval_accuracy': 0.8281122864117169,\n",
       " 'eval_runtime': 34.9968,\n",
       " 'eval_samples_per_second': 280.94,\n",
       " 'eval_steps_per_second': 8.801}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation_mismatched\"], \"mnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 502k/502k [00:00<00:00, 1.82MB/s]\n",
      "Downloading data: 100%|██████████| 151k/151k [00:00<00:00, 839kB/s]\n",
      "Downloading data: 100%|██████████| 114k/114k [00:00<00:00, 547kB/s]\n",
      "Generating train split: 100%|██████████| 5749/5749 [00:00<00:00, 491301.01 examples/s]\n",
      "Generating validation split: 100%|██████████| 1500/1500 [00:00<00:00, 268911.61 examples/s]\n",
      "Generating test split: 100%|██████████| 1379/1379 [00:00<00:00, 250463.14 examples/s]\n",
      "Map: 100%|██████████| 5749/5749 [00:01<00:00, 5027.05 examples/s]\n",
      "Map: 100%|██████████| 1500/1500 [00:00<00:00, 4187.63 examples/s]\n",
      "Map: 100%|██████████| 1379/1379 [00:00<00:00, 6362.51 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.11\n",
      "Setting up gated layer bert.encoder.layer.10\n",
      "Setting up gated layer bert.encoder.layer.9\n",
      "Setting up gated layer bert.encoder.layer.8\n",
      "Collapsing layer bert.encoder.layer.11\n",
      "Collapsing layer bert.encoder.layer.10\n",
      "Collapsing layer bert.encoder.layer.9\n",
      "Collapsing layer bert.encoder.layer.8\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"base-ft-stsb\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('stsb', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-stsb/4_stsb.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-stsb/orig_stsb.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  108311041\n",
      "LC model parameters:  91783681\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6192435622215271,\n",
       " 'eval_pearson': 0.8641723498039111,\n",
       " 'eval_spearmanr': 0.8636361112510562,\n",
       " 'eval_combined_score': 0.8639042305274837,\n",
       " 'eval_runtime': 11.1139,\n",
       " 'eval_samples_per_second': 134.966,\n",
       " 'eval_steps_per_second': 4.229}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"stsb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.570755660533905,\n",
       " 'eval_pearson': 0.8723157966536561,\n",
       " 'eval_spearmanr': 0.872965843659959,\n",
       " 'eval_combined_score': 0.8726408201568076,\n",
       " 'eval_runtime': 9.8722,\n",
       " 'eval_samples_per_second': 151.942,\n",
       " 'eval_steps_per_second': 4.761}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"stsb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1043/1043 [00:00<00:00, 4099.87 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.11\n",
      "Setting up gated layer bert.encoder.layer.10\n",
      "Setting up gated layer bert.encoder.layer.9\n",
      "Setting up gated layer bert.encoder.layer.8\n",
      "Collapsing layer bert.encoder.layer.11\n",
      "Collapsing layer bert.encoder.layer.10\n",
      "Collapsing layer bert.encoder.layer.9\n",
      "Collapsing layer bert.encoder.layer.8\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"base-ft-cola\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('cola', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-cola/4_cola.pth\"))\n",
    "# model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-cola/orig_cola.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  109483778\n",
      "LC model parameters:  92956418\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.3386995792388916,\n",
       " 'eval_matthews_correlation': 0.6104966084654571,\n",
       " 'eval_runtime': 8.1307,\n",
       " 'eval_samples_per_second': 128.279,\n",
       " 'eval_steps_per_second': 4.059}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"cola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6876524686813354,\n",
       " 'eval_matthews_correlation': 0.5963273779713936,\n",
       " 'eval_runtime': 6.7481,\n",
       " 'eval_samples_per_second': 154.563,\n",
       " 'eval_steps_per_second': 4.89}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"cola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.11\n",
      "Setting up gated layer bert.encoder.layer.10\n",
      "Setting up gated layer bert.encoder.layer.9\n",
      "Setting up gated layer bert.encoder.layer.8\n",
      "Collapsing layer bert.encoder.layer.11\n",
      "Collapsing layer bert.encoder.layer.10\n",
      "Collapsing layer bert.encoder.layer.9\n",
      "Collapsing layer bert.encoder.layer.8\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"base-ft-qnli\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('qnli', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-qnli/4_qnli.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-qnli/orig_qnli.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  108311810\n",
      "LC model parameters:  91784450\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='171' max='171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [171/171 00:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2749437689781189,\n",
       " 'eval_accuracy': 0.9099395936298736,\n",
       " 'eval_runtime': 40.4869,\n",
       " 'eval_samples_per_second': 134.933,\n",
       " 'eval_steps_per_second': 4.224}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"qnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='171' max='171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [171/171 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3908904194831848,\n",
       " 'eval_accuracy': 0.8980413692110562,\n",
       " 'eval_runtime': 19.5088,\n",
       " 'eval_samples_per_second': 280.028,\n",
       " 'eval_steps_per_second': 8.765}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"qnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.11\n",
      "Setting up gated layer bert.encoder.layer.10\n",
      "Setting up gated layer bert.encoder.layer.9\n",
      "Setting up gated layer bert.encoder.layer.8\n",
      "Collapsing layer bert.encoder.layer.11\n",
      "Collapsing layer bert.encoder.layer.10\n",
      "Collapsing layer bert.encoder.layer.9\n",
      "Collapsing layer bert.encoder.layer.8\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"base-ft-rte\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('rte', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-rte/4_rte.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/base-ft-rte/orig_rte.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.309451699256897,\n",
       " 'eval_accuracy': 0.6570397111913358,\n",
       " 'eval_runtime': 1.0872,\n",
       " 'eval_samples_per_second': 254.775,\n",
       " 'eval_steps_per_second': 8.278}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"rte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0787622928619385,\n",
       " 'eval_accuracy': 0.6137184115523465,\n",
       " 'eval_runtime': 1.0057,\n",
       " 'eval_samples_per_second': 275.426,\n",
       " 'eval_steps_per_second': 8.949}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"rte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  109483778\n",
      "LC model parameters:  92956418\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.23\n",
      "Setting up gated layer bert.encoder.layer.22\n",
      "Setting up gated layer bert.encoder.layer.21\n",
      "Setting up gated layer bert.encoder.layer.20\n",
      "Collapsing layer bert.encoder.layer.23\n",
      "Collapsing layer bert.encoder.layer.22\n",
      "Collapsing layer bert.encoder.layer.21\n",
      "Collapsing layer bert.encoder.layer.20\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"large-ft-qqp\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('qqp', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-qqp/4_qqp.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-qqp/orig_qqp.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  335143938\n",
      "LC model parameters:  305767426\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1264' max='1264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1264/1264 12:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.24002790451049805,\n",
       " 'eval_accuracy': 0.9133316843927777,\n",
       " 'eval_f1': 0.885227644939404,\n",
       " 'eval_combined_score': 0.8992796646660908,\n",
       " 'eval_runtime': 742.1176,\n",
       " 'eval_samples_per_second': 54.479,\n",
       " 'eval_steps_per_second': 1.703}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"qqp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1264' max='1264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1264/1264 11:49]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.27776554226875305,\n",
       " 'eval_accuracy': 0.9102151867425179,\n",
       " 'eval_f1': 0.878236951563129,\n",
       " 'eval_combined_score': 0.8942260691528234,\n",
       " 'eval_runtime': 710.5415,\n",
       " 'eval_samples_per_second': 56.9,\n",
       " 'eval_steps_per_second': 1.779}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"qqp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.23\n",
      "Setting up gated layer bert.encoder.layer.22\n",
      "Setting up gated layer bert.encoder.layer.21\n",
      "Setting up gated layer bert.encoder.layer.20\n",
      "Collapsing layer bert.encoder.layer.23\n",
      "Collapsing layer bert.encoder.layer.22\n",
      "Collapsing layer bert.encoder.layer.21\n",
      "Collapsing layer bert.encoder.layer.20\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"large-ft-qnli\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('qnli', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-qnli/4_qnli.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-qnli/orig_qnli.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  335143938\n",
      "LC model parameters:  305767426\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='171' max='171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [171/171 01:53]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9608904719352722,\n",
       " 'eval_accuracy': 0.8927329306241991,\n",
       " 'eval_runtime': 114.7363,\n",
       " 'eval_samples_per_second': 47.614,\n",
       " 'eval_steps_per_second': 1.49}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"qnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='171' max='171' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [171/171 01:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2726178765296936,\n",
       " 'eval_accuracy': 0.9139666849716274,\n",
       " 'eval_runtime': 75.018,\n",
       " 'eval_samples_per_second': 72.823,\n",
       " 'eval_steps_per_second': 2.279}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"qnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9832/9832 [00:02<00:00, 3556.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.23\n",
      "Setting up gated layer bert.encoder.layer.22\n",
      "Setting up gated layer bert.encoder.layer.21\n",
      "Setting up gated layer bert.encoder.layer.20\n",
      "Collapsing layer bert.encoder.layer.23\n",
      "Collapsing layer bert.encoder.layer.22\n",
      "Collapsing layer bert.encoder.layer.21\n",
      "Collapsing layer bert.encoder.layer.20\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"large-ft-mnli\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('mnli', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-mnli/4_mnli.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-mnli/orig_mnli.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  335144963\n",
      "LC model parameters:  305768451\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='307' max='307' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [307/307 03:24]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.39440056681632996,\n",
       " 'eval_accuracy': 0.862761079979623,\n",
       " 'eval_runtime': 205.6252,\n",
       " 'eval_samples_per_second': 47.732,\n",
       " 'eval_steps_per_second': 1.493}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation_matched\"], \"mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='308' max='308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [308/308 03:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.39168038964271545,\n",
       " 'eval_accuracy': 0.8610659072416599,\n",
       " 'eval_runtime': 208.7655,\n",
       " 'eval_samples_per_second': 47.096,\n",
       " 'eval_steps_per_second': 1.475}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation_mismatched\"], \"mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='307' max='307' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [307/307 03:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.520072340965271,\n",
       " 'eval_accuracy': 0.8663270504330107,\n",
       " 'eval_runtime': 191.3468,\n",
       " 'eval_samples_per_second': 51.294,\n",
       " 'eval_steps_per_second': 1.604}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation_matched\"], \"mnli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='308' max='308' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [308/308 03:10]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5458422899246216,\n",
       " 'eval_accuracy': 0.8552685109845403,\n",
       " 'eval_runtime': 190.7154,\n",
       " 'eval_samples_per_second': 51.553,\n",
       " 'eval_steps_per_second': 1.615}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation_mismatched\"], \"mnli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.23\n",
      "Setting up gated layer bert.encoder.layer.22\n",
      "Setting up gated layer bert.encoder.layer.21\n",
      "Setting up gated layer bert.encoder.layer.20\n",
      "Collapsing layer bert.encoder.layer.23\n",
      "Collapsing layer bert.encoder.layer.22\n",
      "Collapsing layer bert.encoder.layer.21\n",
      "Collapsing layer bert.encoder.layer.20\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"large-ft-cola\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('cola', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-cola/4_cola.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-cola/orig_cola.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  335143938\n",
      "LC model parameters:  305767426\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.4323997497558594,\n",
       " 'eval_matthews_correlation': 0.6256921039386708,\n",
       " 'eval_runtime': 21.2331,\n",
       " 'eval_samples_per_second': 49.121,\n",
       " 'eval_steps_per_second': 1.554}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"cola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6261414289474487,\n",
       " 'eval_matthews_correlation': 0.6259118543644094,\n",
       " 'eval_runtime': 20.3845,\n",
       " 'eval_samples_per_second': 51.166,\n",
       " 'eval_steps_per_second': 1.619}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"cola\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.23\n",
      "Setting up gated layer bert.encoder.layer.22\n",
      "Setting up gated layer bert.encoder.layer.21\n",
      "Setting up gated layer bert.encoder.layer.20\n",
      "Collapsing layer bert.encoder.layer.23\n",
      "Collapsing layer bert.encoder.layer.22\n",
      "Collapsing layer bert.encoder.layer.21\n",
      "Collapsing layer bert.encoder.layer.20\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"large-ft-mrpc\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('mrpc', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-mrpc/4_mrpc.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-mrpc/orig_mrpc.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  335143938\n",
      "LC model parameters:  305767426\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.272477149963379,\n",
       " 'eval_accuracy': 0.8333333333333334,\n",
       " 'eval_f1': 0.8827586206896552,\n",
       " 'eval_combined_score': 0.8580459770114943,\n",
       " 'eval_runtime': 8.4007,\n",
       " 'eval_samples_per_second': 48.568,\n",
       " 'eval_steps_per_second': 1.547}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13/13 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5088669061660767,\n",
       " 'eval_accuracy': 0.8529411764705882,\n",
       " 'eval_f1': 0.896551724137931,\n",
       " 'eval_combined_score': 0.8747464503042597,\n",
       " 'eval_runtime': 7.8904,\n",
       " 'eval_samples_per_second': 51.708,\n",
       " 'eval_steps_per_second': 1.648}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"mrpc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SST2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.23\n",
      "Setting up gated layer bert.encoder.layer.22\n",
      "Setting up gated layer bert.encoder.layer.21\n",
      "Setting up gated layer bert.encoder.layer.20\n",
      "Collapsing layer bert.encoder.layer.23\n",
      "Collapsing layer bert.encoder.layer.22\n",
      "Collapsing layer bert.encoder.layer.21\n",
      "Collapsing layer bert.encoder.layer.20\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"large-ft-sst2\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('sst2', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-sst2/4_sst2.pth\"))\n",
    "# model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-sst2/orig_sst2.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  335143938\n",
      "LC model parameters:  305767426\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.22841081023216248,\n",
       " 'eval_accuracy': 0.9346330275229358,\n",
       " 'eval_runtime': 18.4591,\n",
       " 'eval_samples_per_second': 47.239,\n",
       " 'eval_steps_per_second': 1.517}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2305382490158081,\n",
       " 'eval_accuracy': 0.930045871559633,\n",
       " 'eval_runtime': 16.453,\n",
       " 'eval_samples_per_second': 52.999,\n",
       " 'eval_steps_per_second': 1.702}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"sst2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STSB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.23\n",
      "Setting up gated layer bert.encoder.layer.22\n",
      "Setting up gated layer bert.encoder.layer.21\n",
      "Setting up gated layer bert.encoder.layer.20\n",
      "Collapsing layer bert.encoder.layer.23\n",
      "Collapsing layer bert.encoder.layer.22\n",
      "Collapsing layer bert.encoder.layer.21\n",
      "Collapsing layer bert.encoder.layer.20\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"large-ft-stsb\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('stsb', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-stsb/4_stsb.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-stsb/orig_stsb.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  335142913\n",
      "LC model parameters:  305766401\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5596344470977783,\n",
       " 'eval_pearson': 0.8770772340838442,\n",
       " 'eval_spearmanr': 0.8758346837155176,\n",
       " 'eval_combined_score': 0.876455958899681,\n",
       " 'eval_runtime': 13.2391,\n",
       " 'eval_samples_per_second': 113.301,\n",
       " 'eval_steps_per_second': 3.55}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"stsb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='47' max='47' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [47/47 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4750456213951111,\n",
       " 'eval_pearson': 0.8968027940356771,\n",
       " 'eval_spearmanr': 0.8930373272445522,\n",
       " 'eval_combined_score': 0.8949200606401146,\n",
       " 'eval_runtime': 12.647,\n",
       " 'eval_samples_per_second': 118.605,\n",
       " 'eval_steps_per_second': 3.716}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"stsb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RTE   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up gated layer bert.encoder.layer.23\n",
      "Setting up gated layer bert.encoder.layer.22\n",
      "Setting up gated layer bert.encoder.layer.21\n",
      "Setting up gated layer bert.encoder.layer.20\n",
      "Collapsing layer bert.encoder.layer.23\n",
      "Collapsing layer bert.encoder.layer.22\n",
      "Collapsing layer bert.encoder.layer.21\n",
      "Collapsing layer bert.encoder.layer.20\n"
     ]
    }
   ],
   "source": [
    "model_base, tokenizer = get_classification_bert_model(pre_trained_model_name=huggingface_models[\"large-ft-rte\"])\n",
    "train_dataloader, validation_dataloader, dataset = get_glue_task_dataset('rte', tokenizer)\n",
    "model_LC = get_LC_model_bert(model_base, num_GP_layers=4)\n",
    "model_LC.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-rte/4_rte.pth\"))\n",
    "model_base.load_state_dict(torch.load(\"/scr/models/LC/models_archive/Bert/large-ft-rte/orig_rte.pth\"))\n",
    "collapse_model(model_LC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model parameters:  333581314\n",
      "LC model parameters:  304204802\n"
     ]
    }
   ],
   "source": [
    "print(\"base model parameters: \", get_num_parameters(model_base))\n",
    "print(\"LC model parameters: \", get_num_parameters(model_LC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/GP/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.7359601259231567,\n",
       " 'eval_accuracy': 0.6642599277978339,\n",
       " 'eval_runtime': 7.5333,\n",
       " 'eval_samples_per_second': 36.77,\n",
       " 'eval_steps_per_second': 1.195}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_base, dataset[\"validation\"], \"rte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9' max='9' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9/9 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2795310020446777,\n",
       " 'eval_accuracy': 0.7148014440433214,\n",
       " 'eval_runtime': 2.2664,\n",
       " 'eval_samples_per_second': 122.223,\n",
       " 'eval_steps_per_second': 3.971}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard_evaluate(model_LC, dataset[\"validation\"], \"rte\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
