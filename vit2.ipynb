{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from collections import OrderedDict, defaultdict\n",
    "from typing import Union, List\n",
    "from utils import *\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchprofile import profile_macs\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "assert torch.cuda.is_available(), \\\n",
    "\"CUDA support is not available.\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "import LiveTune as lt\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_dataloader(\"imagenet\", 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on VIT Tiny_patch_16_augreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vit = timm.create_model(\"vit_tiny_patch16_224.augreg_in21k_ft_in1k\", pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.34799194335938"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(base_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n"
     ]
    }
   ],
   "source": [
    "collapsible_vit = get_collapsible_model(base_vit, fraction=.25, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/finetuned_1epoch_frac025_nolc_2.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.50399780273438"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/finetuned_11epoch_frac025_lc.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.11.mlp 0.9334723353385925\n",
      "blocks.10.mlp 0.829644501209259\n",
      "blocks.9.mlp 0.5449391007423401\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapsible_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73.13199615478516"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 5717416 -> 5717419 (1.00x)\n"
     ]
    }
   ],
   "source": [
    "parameters_base = get_num_parameters(base_vit)\n",
    "parameters_collapsible = get_num_parameters(collapsible_vit)\n",
    "print(f\"Parameters: {parameters_base} -> {parameters_collapsible} ({parameters_collapsible/parameters_base:.2f}x)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.6.mlp\n",
      "Collapsing layer blocks.5.mlp\n",
      "Collapsing layer blocks.4.mlp\n",
      "Collapsing layer blocks.3.mlp\n",
      "Collapsing layer blocks.2.mlp\n",
      "Collapsing layer blocks.1.mlp\n",
      "Collapsing layer blocks.0.mlp\n"
     ]
    }
   ],
   "source": [
    "collapsible_vit = get_collapsible_model(base_vit, fraction=1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/collapsible_vit_tiny_16.augreg_in21k_ft_10ephock_nolc.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69.33999633789062"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After 11 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/collapsible_vit_tiny_16augreg_in21k_ft_15ephock_nolc.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68.75599670410156"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:\n",
    "### Updated the numbers in the paper. file was not saved properly. So re run the experiments in this file (the training is finished and in models archive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test vit_base_patch16_224.orig_in21k_ft_in1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vit = timm.create_model(\"vit_base_patch16_224.orig_in21k_ft_in1k\", pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.43199920654297"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(base_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total params in MLP : 56M -> savings per layer collapse ~4M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86567656"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_parameters(base_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n"
     ]
    }
   ],
   "source": [
    "collapsible_vit = get_collapsible_model(base_vit, fraction=.1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/base/finetuned_7epoch_frac01_lc.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.50800323486328"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.11.mlp 0.9902544021606445\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapsible_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n"
     ]
    }
   ],
   "source": [
    "collapse_model(collapsible_vit, fraction=.1, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82435816"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_parameters(collapsible_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.50599670410156"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::scaled_dot_product_attention\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has test accuracy=81.43%\n",
      "model has top5 accuracy=0.96%\n",
      "model has size=330.23 MiB\n",
      "model has macs=16.85 Gmacs\n",
      "average inference time is 0.0064 seconds\n",
      "model has 86.57 M parameters\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(base_vit, dataloader=dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::scaled_dot_product_attention\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has test accuracy=79.51%\n",
      "model has top5 accuracy=0.95%\n",
      "model has size=314.47 MiB\n",
      "model has macs=16.04 Gmacs\n",
      "average inference time is 0.0045 seconds\n",
      "model has 82.44 M parameters\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(collapsible_vit, dataloader=dataloader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 percent reduction in parameter count.\n",
    "\n",
    "0.2 percent reduction in accuracy.\n",
    "\n",
    "30 percent reduction in inference time.\n",
    "\n",
    "5 percent reduction in total MACs.\n",
    "\n",
    "lc was done with lc=1.0\n",
    "Current results with the bad version of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_vit = timm.create_model(\"vit_base_patch16_224.orig_in21k_ft_in1k\", pretrained=True).to(device)\n",
    "collapsible_vit = get_collapsible_model(base_vit, fraction=.1, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/base/new_finetuned_5epoch_frac01_lc.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n"
     ]
    }
   ],
   "source": [
    "collapse_model(collapsible_vit, fraction=.1, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.17399597167969"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::scaled_dot_product_attention\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has test accuracy=82.17%\n",
      "model has top5 accuracy=0.96%\n",
      "model has size=314.47 MiB\n",
      "model has macs=16.04 Gmacs\n",
      "average inference time is 0.0042 seconds\n",
      "model has 82.44 M parameters\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(collapsible_vit, dataloader=dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n"
     ]
    }
   ],
   "source": [
    "base_vit = timm.create_model(\"vit_base_patch16_224.orig_in21k_ft_in1k\", pretrained=True).to(device)\n",
    "collapsible_vit = get_collapsible_model(base_vit, fraction=.1, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/base/new_finetuned_5epoch_frac01_lc.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=1/6, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/base/new_finetuned_5epoch_frac01_lc_collapsing2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::scaled_dot_product_attention\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has test accuracy=80.31%\n",
      "model has top5 accuracy=0.95%\n",
      "model has size=298.71 MiB\n",
      "model has macs=15.23 Gmacs\n",
      "average inference time is 0.0037 seconds\n",
      "model has 78.30 M parameters\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(collapsible_vit, dataloader=dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vit = timm.create_model(\"vit_large_patch16_224.augreg_in21k_ft_in1k\", pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85.68199920654297"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(base_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "304326632"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_parameters(base_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.23.mlp\n",
      "Collapsing layer blocks.22.mlp\n"
     ]
    }
   ],
   "source": [
    "collapse_vit = get_collapsible_model(base_vit, fraction=.1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_vit.load_state_dict(torch.load(\"./models_archive/vit/large/finetuned_2epoch_frac01_nolc.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85.70199584960938"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapse_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapse_vit.load_state_dict(torch.load(\"./models_archive/vit/large/finetuned_17epoch_frac01_lc.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84.30799865722656"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapse_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.23.mlp 0.9962775707244873\n",
      "blocks.22.mlp 0.9683569073677063\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapse_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.23.mlp\n",
      "Collapsing layer blocks.22.mlp\n"
     ]
    }
   ],
   "source": [
    "collapse_model(collapse_vit, fraction=.1, threshold=0.05, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::scaled_dot_product_attention\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has test accuracy=84.22%\n",
      "model has top5 accuracy=0.97%\n",
      "model has size=1104.88 MiB\n",
      "model has macs=56.77 Gmacs\n",
      "average inference time is 0.0125 seconds\n",
      "model has 289.64 M parameters\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(collapse_vit, dataloader=dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::scaled_dot_product_attention\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has test accuracy=85.68%\n",
      "model has top5 accuracy=0.98%\n",
      "model has size=1160.91 MiB\n",
      "model has macs=59.66 Gmacs\n",
      "average inference time is 0.0130 seconds\n",
      "model has 304.33 M parameters\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(base_vit, dataloader=dataloader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT Small\n",
    "## vit_small_patch16_224.augreg_in21k_ft_in1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vit = timm.create_model(\"vit_small_patch16_224.augreg_in21k_ft_in1k\", pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22050664"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_parameters(base_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81.38200378417969"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(base_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n"
     ]
    }
   ],
   "source": [
    "collapse_vit = get_collapsible_model(base_vit, fraction=.2, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapse_vit.load_state_dict(torch.load(\"./models_archive/vit/small/finetuned_1epoch_frac02_nolc.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.11.mlp 0.31300053000450134\n",
      "blocks.10.mlp -2.9146413803100586\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapse_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32.51799774169922"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapse_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapse_vit.load_state_dict(torch.load(\"./models_archive/vit/small/finetuned_13epoch_frac02_lc.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.26799774169922"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapse_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.11.mlp 0.9834568500518799\n",
      "blocks.10.mlp -0.02318074367940426\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapse_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Not collapsible\n"
     ]
    }
   ],
   "source": [
    "collapse_model(collapse_vit, fraction=.2, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "79.20999145507812"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapse_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::scaled_dot_product_attention\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has test accuracy=81.38%\n",
      "model has top5 accuracy=0.96%\n",
      "model has size=84.12 MiB\n",
      "model has macs=4.24 Gmacs\n",
      "average inference time is 0.0043 seconds\n",
      "model has 22.05 M parameters\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(base_vit, dataloader=dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::scaled_dot_product_attention\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::prelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has test accuracy=79.21%\n",
      "model has top5 accuracy=0.95%\n",
      "model has size=80.17 MiB\n",
      "model has macs=4.04 Gmacs\n",
      "average inference time is 0.0061 seconds\n",
      "model has 21.02 M parameters\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(collapse_vit, dataloader=dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapse_vit = get_collapsible_model(base_vit, fraction=.2, device=device)\n",
    "collapse_vit.load_state_dict(torch.load(\"./models_archive/vit/small/finetuned_1epoch_frac02_nolc.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52.433998107910156"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapse_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_vit = timm.create_model(\"vit_small_patch16_224.augreg_in21k_ft_in1k\", pretrained=True).to(device)\n",
    "collapsible_vit = get_collapsible_model(base_vit, fraction=.1, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/small/new_finetuned_5epoch_frac01_lc.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, fraction=.1, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::scaled_dot_product_attention\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has test accuracy=80.96%\n",
      "model has top5 accuracy=0.96%\n",
      "model has size=80.17 MiB\n",
      "model has macs=4.04 Gmacs\n",
      "average inference time is 0.0043 seconds\n",
      "model has 21.02 M parameters\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(collapsible_vit, dataloader=dataloader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n"
     ]
    }
   ],
   "source": [
    "base_vit = timm.create_model(\"vit_small_patch16_224.augreg_in21k_ft_in1k\", pretrained=True).to(device)\n",
    "collapsible_vit = get_collapsible_model(base_vit, fraction=.1, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/small/new_finetuned_5epoch_frac01_lc.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, fraction=.1, device=device, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=1/6, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/small/new_finetuned_5epoch_collapsing2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, fraction=1/6, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::expand\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::reshape\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::permute\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::unbind\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::scaled_dot_product_attention\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n",
      "/home/soheil/miniconda3/envs/hardwareAcc/lib/python3.10/site-packages/torchprofile/profile.py:22: UserWarning: No handlers found: \"aten::gelu\". Skipped.\n",
      "  warnings.warn('No handlers found: \"{}\". Skipped.'.format(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model has test accuracy=79.74%\n",
      "model has top5 accuracy=0.95%\n",
      "model has size=76.23 MiB\n",
      "model has macs=3.84 Gmacs\n",
      "average inference time is 0.0040 seconds\n",
      "model has 19.98 M parameters\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(collapsible_vit, dataloader=dataloader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiny\n",
    "base_vit = timm.create_model(\"vit_tiny_patch16_224.augreg_in21k_ft_in1k\", pretrained=True).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc : 75.34"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsible_vit = get_collapsible_model(base_vit, fraction=1/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing1.pth\", map_location=device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.11.mlp 0.9937456250190735\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapsible_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n"
     ]
    }
   ],
   "source": [
    "collapse_model(collapsible_vit, fraction=1/12, threshold=0.05, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.78799438476562"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Not collapsible\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsible_vit = get_collapsible_model(base_vit, fraction=2/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_10epoch_frac0.166_lc2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing2.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.11.mlp 1\n",
      "blocks.10.mlp 0.9963091611862183\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapsible_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n"
     ]
    }
   ],
   "source": [
    "collapse_model(collapsible_vit, fraction=2/12, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75.33799743652344"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(collapsible_vit.state_dict(), \"./models_archive/vit/tiny/sensitivity_analysis_collapsed2.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Not collapsible\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n"
     ]
    }
   ],
   "source": [
    "collapsible_vit = get_collapsible_model(base_vit, fraction=2/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_10epoch_frac0.166_lc2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, fraction=2/12, device=device, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=3/12, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing3.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.11.mlp 1\n",
      "blocks.10.mlp 1\n",
      "blocks.9.mlp 0.9955717921257019\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapsible_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n"
     ]
    }
   ],
   "source": [
    "collapse_model(collapsible_vit, fraction=3/12, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.41999816894531"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(collapsible_vit.state_dict(), \"./models_archive/vit/tiny/sensitivity_analysis_collapsed3.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Not collapsible\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collapsible_vit = get_collapsible_model(base_vit, fraction=2/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_10epoch_frac0.166_lc2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, fraction=2/12, device=device, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=3/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing3.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, fraction=3/12, device=device, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=4/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing4.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.11.mlp 1\n",
      "blocks.10.mlp 1\n",
      "blocks.9.mlp 1\n",
      "blocks.8.mlp 0.9978395104408264\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapsible_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n"
     ]
    }
   ],
   "source": [
    "collapse_model(collapsible_vit, fraction=4/12, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "73.13199615478516"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(collapsible_vit.state_dict(), \"./models_archive/vit/tiny/sensitivity_analysis_collapsed4.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=5/12, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.11.mlp 1\n",
      "blocks.10.mlp 1\n",
      "blocks.9.mlp 1\n",
      "blocks.8.mlp 1\n",
      "blocks.7.mlp 0.009999999776482582\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapsible_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Not collapsible\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_vit = timm.create_model(\"vit_tiny_patch16_224.augreg_in21k_ft_in1k\", pretrained=True).to(device)\n",
    "collapsible_vit = get_collapsible_model(base_vit, fraction=2/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_10epoch_frac0.166_lc2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, fraction=2/12, device=device, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=3/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing3.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=4/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing4.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=5/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing5.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.11.mlp 1\n",
      "blocks.10.mlp 1\n",
      "blocks.9.mlp 1\n",
      "blocks.8.mlp 1\n",
      "blocks.7.mlp 0.9954009056091309\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapsible_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n"
     ]
    }
   ],
   "source": [
    "collapse_model(collapsible_vit, fraction=5/12, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71.3499984741211"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.3659989057994"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_num_parameters(collapsible_vit)/get_num_parameters(base_vit) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.6.mlp\n",
      "blocks.11.mlp 1\n",
      "blocks.10.mlp 1\n",
      "blocks.9.mlp 1\n",
      "blocks.8.mlp 1\n",
      "blocks.7.mlp 1\n",
      "blocks.6.mlp 0.009999999776482582\n"
     ]
    }
   ],
   "source": [
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=6/12, device=device)\n",
    "get_model_collapsible_slopes(collapsible_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Not collapsible\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.6.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.6.mlp\n"
     ]
    }
   ],
   "source": [
    "base_vit = timm.create_model(\"vit_tiny_patch16_224.augreg_in21k_ft_in1k\", pretrained=True).to(device)\n",
    "collapsible_vit = get_collapsible_model(base_vit, fraction=2/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_10epoch_frac0.166_lc2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, fraction=2/12, device=device, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=3/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing3.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=4/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing4.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=5/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing5.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=6/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing6.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, fraction=6/12, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.11.mlp 1\n",
      "blocks.10.mlp 1\n",
      "blocks.9.mlp 1\n",
      "blocks.8.mlp 1\n",
      "blocks.7.mlp 1\n",
      "blocks.6.mlp 1\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapsible_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68.76799774169922"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Not collapsible\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.6.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.6.mlp\n",
      "Collapsing layer blocks.5.mlp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_vit = timm.create_model(\"vit_tiny_patch16_224.augreg_in21k_ft_in1k\", pretrained=True).to(device)\n",
    "collapsible_vit = get_collapsible_model(base_vit, fraction=2/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_10epoch_frac0.166_lc2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, fraction=2/12, device=device, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=3/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing3.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=4/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing4.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=5/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing5.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=6/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing6.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=7/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing7.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.6.mlp\n",
      "Collapsing layer blocks.5.mlp\n"
     ]
    }
   ],
   "source": [
    "collapse_model(collapsible_vit, fraction=7/12, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "66.93199920654297"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Not collapsible\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.6.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.6.mlp\n",
      "Collapsing layer blocks.5.mlp\n",
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.6.mlp\n",
      "Collapsing layer blocks.5.mlp\n",
      "Collapsing layer blocks.4.mlp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_vit = timm.create_model(\"vit_tiny_patch16_224.augreg_in21k_ft_in1k\", pretrained=True).to(device)\n",
    "collapsible_vit = get_collapsible_model(base_vit, fraction=2/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_10epoch_frac0.166_lc2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing2.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, fraction=2/12, device=device, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=3/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing3.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=4/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing4.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=5/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing5.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=6/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing6.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=7/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing7.pth\", map_location=device))\n",
    "collapse_model(collapsible_vit, threshold=0.05)\n",
    "collapsible_vit = get_collapsible_model(collapsible_vit, fraction=8/12, device=device)\n",
    "collapsible_vit.load_state_dict(torch.load(\"./models_archive/vit/tiny/sensitivity_analysis_collapsing8.pth\", map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.11.mlp 1\n",
      "blocks.10.mlp 1\n",
      "blocks.9.mlp 1\n",
      "blocks.8.mlp 1\n",
      "blocks.7.mlp 1\n",
      "blocks.6.mlp 1\n",
      "blocks.5.mlp 1\n",
      "blocks.4.mlp 0.9587531089782715\n"
     ]
    }
   ],
   "source": [
    "get_model_collapsible_slopes(collapsible_vit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collapse_model(collapsible_vit, fraction=8/12, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64.0219955444336"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collapsing layer blocks.11.mlp\n",
      "Collapsing layer blocks.10.mlp\n",
      "Collapsing layer blocks.9.mlp\n",
      "Collapsing layer blocks.8.mlp\n",
      "Collapsing layer blocks.7.mlp\n",
      "Collapsing layer blocks.6.mlp\n",
      "Collapsing layer blocks.5.mlp\n",
      "Collapsing layer blocks.4.mlp\n"
     ]
    }
   ],
   "source": [
    "collapse_model(collapsible_vit, fraction=8/12, device=device, threshold=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.5359992980957"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(collapsible_vit, dataloader=dataloader['val'], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hardwareAcc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
